{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIDS based on Network Flow Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are previous data structures really hardware friendly?\n",
    "\n",
    "Even though hash tables and collision resistant mechanisms such as linked lists are nice solutions, linked lists are not tailored for hardware.  Also, one-to-one mapping requires a considerable amount memory as the number of encountered flows could be in millions. \n",
    "\n",
    "A hardware friendly alternative is to use **sketches**, which additionally have some built-in collision resistance mechanisms. Instead of one-to-one mapping, one single flow is mapped to multiple counters and each counter is shared by multiple flows in the case of collisions. Sketches require less memory as the flowIDs don't have to be stored. As for the downside of using sketches, there is a possibility of overestimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Sketch\n",
    "\n",
    "A CM sketch is represented by a 2D array of counters with width w and depth d. The depth corresponds to the number of hash functions that is used.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/counting/CM_sketch.png\"/>\n",
    "</center>\n",
    "\n",
    "In the example above, h<sub>1</sub>, h<sub>2</sub>,...,h<sub>d</sub> are independent hash values on the FlowID *f1*. Each FlowID is mapped to *d* counters in the sketch during an update operation. When the CM sketch is queried the minimum of all the *d* counters is given as result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "data_file = 'data/dataset_packets_v2.npy'\n",
    "labels_file = 'data/dataset_labels_v1.npy'\n",
    "\n",
    "dataset = NIDSDataset(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing CM Sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 22.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import hashlib\n",
    "\"\"\" CM Sketch parameters and functions  \"\"\"    \n",
    "m = 256\n",
    "d = 4\n",
    "\n",
    "#initializes an empty 2-d array\n",
    "tables = []\n",
    "for i in range(d):\n",
    "    table = array.array(\"l\", (0 for i in range(m))) # \"l\" is the typecode indicating that the type is signed long\n",
    "    tables.append(table)\n",
    "    \n",
    "# Here, instead of using d independant hashes, the output of md5 hash is split into d hash values.\n",
    "def _hash(flowid):\n",
    "    \"\"\" hash computation \"\"\"\n",
    "    m=256\n",
    "    d=4\n",
    "    md5 = hashlib.md5(str(hash(flowid)).encode('utf-8'))\n",
    "    for i in range(d):\n",
    "        md5.update(str(i).encode('utf-8'))\n",
    "        yield int(md5.hexdigest(), 16) % m # yield gives a generator object and has to be iterated to read the values.\n",
    "        \n",
    "def add_cms(flowid, value):\n",
    "    \"\"\"Add a value to hashtable by its key and update the contents if the cell is not empty\"\"\"\n",
    "    # get the d indexed locations of the sketch by hashing. Uncomment 'indices =' and complete the code.\n",
    "    \"\"\"WRITE code here \"\"\" \n",
    "    indices = _hash(flowid)\n",
    "    \n",
    "    # Iterate through tables and indices and update the value stored in each indexed location\n",
    "    # Whether the location is empty or not, just add the value to the already existing value\n",
    "    for table, i in zip(tables,indices):\n",
    "        \"\"\" WRITE Code here \"\"\"\n",
    "        table[i] += value\n",
    "\n",
    "def query_cms(flowid):\n",
    "    \"\"\"Get a value by key\"\"\"\n",
    "    # get the d indexed locations of the sketch by hashing. Uncomment 'indices =' and complete the code.\n",
    "    \"\"\"WRITE code here \"\"\" \n",
    "    indices = _hash(flowid)\n",
    "    \n",
    "    # Iterate through tables and indices and return the minimum of the values stored in the indexed locations\n",
    "    \"\"\" WRITE Code \"\"\"\n",
    "    return min(table[i] for table, i in zip(tables, indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the dataset again and determine which of the flowids exhibits anomalous behaviour by exceeding the allocated bandwidth. \n",
    "\n",
    "(***HINT***: you can recover most of the work from your previous exercises.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 22.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 256\n",
    "d = 4\n",
    "#resets the sketch to an empty 2-d array\n",
    "tables = []\n",
    "for i in range(d):\n",
    "    table = array.array(\"l\", (0 for i in range(m))) # \"l\" is the typecode indicating that the type is signed long\n",
    "    tables.append(table)\n",
    "    \n",
    "\"\"\" Now, reading the dataset again to update the hashtable. you can Copy and \"\"\"\n",
    "\"\"\" paste the code from the previous Exercise. \"\"\"\n",
    "\n",
    "wordcounter=0\n",
    "flowid = \"\"     # flow id\n",
    "flowvolume = \"\" # flow volume\n",
    "flowlist = []  # keeps a list to store flows\n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "\n",
    "    decision_is_made = 0 # decision_is_made = 1 when ethertype is not 0x0800 or packet is neither TCP nor UDP\n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "    flowvolume = \"\"\n",
    "    flowid_complete = 0\n",
    "\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "        # stop parsing if a decission is made\n",
    "        if decision_is_made == 0:\n",
    "\n",
    "            # examine if Ethertype is 0x0800 - in link layer header\n",
    "            # if Ethertype is not equal to 0x0800, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if wordcounter == 3:\n",
    "                if(word[0] == 8) and (word[1] == 0):\n",
    "                    decision_is_made = 0\n",
    "                else:\n",
    "                    decision_is_made = 1\n",
    "                    break\n",
    "            # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "            # if proto is not tcp or udp, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if wordcounter == 5:\n",
    "                if(word[3] == 6)or(word[3] == 17):\n",
    "                    decision_is_made = 0\n",
    "                else:\n",
    "                    decision_is_made = 1\n",
    "                    break\n",
    "                    \n",
    "            # extract Total length (flow volume) - in network layer header\n",
    "            # hint: convert to hex and concatanate the bytes\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if(wordcounter == 4):\n",
    "                flowvolume += hex(word[0])[2:] # ip len 1/2\n",
    "                flowvolume += hex(word[1])[2:]  # ip len 2/2\n",
    "                \n",
    "            # Extract flowid. flowid is (sorce address, dest address, source port, dest port)\n",
    "            # hint: convert to hex and remove 0x. concatanate the addresses and ports\n",
    "            \n",
    "            # extract Source Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if wordcounter == 6:\n",
    "                flowid += hex(word[2])[2:]  # ip SA 1/4\n",
    "                flowid += hex(word[3])[2:]  # ip SA 2/4\n",
    "            if wordcounter == 7:\n",
    "                flowid += hex(word[0])[2:]  # ip SA 3/4\n",
    "                flowid += hex(word[1])[2:]  # ip SA 4/4\n",
    "            # extract Destination Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if wordcounter == 7:\n",
    "                flowid += hex(word[2])[2:]  # ip DA 1/4\n",
    "                flowid += hex(word[3])[2:]  # ip DA 2/4\n",
    "            if wordcounter == 8:\n",
    "                flowid += hex(word[0])[2:]  # ip DA 3/4\n",
    "                flowid += hex(word[1])[2:]  # ip DA 4/4\n",
    "            \n",
    "            # extract source port estination port - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            if wordcounter == 8:\n",
    "                flowid += hex(word[2])[2:]  # ip SPort 1/2\n",
    "                flowid += hex(word[3])[2:]  # ip SPort 2/2\n",
    "\n",
    "            # examine Destination port - in transport layer header\n",
    "            # If the flowid is complete, set the flag flowid_complete to 1 and break out of the loop\n",
    "            \"\"\" WRITE code here \"\"\"\n",
    "            if wordcounter == 9:\n",
    "                flowid += hex(word[0])[2:]  # ip DPort 1/2\n",
    "                flowid += hex(word[1])[2:]  # ip DPort 2/2\n",
    "                flowid_complete = 1\n",
    "                break\n",
    "            \n",
    "        wordcounter += 1\n",
    "        \n",
    "    if(flowid_complete == 1): \n",
    "        if flowid not in flowlist:\n",
    "            flowlist.append(flowid)\n",
    "            \n",
    "        # Convert the flow volume to integer\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        flowvolume = (int(\"0x\"+flowvolume,16))\n",
    "\n",
    "        \"\"\" Updating the table \"\"\"\n",
    "        # add flowid and flowvolume to the hashtable using the function\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        add_cms(flowid,flowvolume)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 22.1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0a8a32c0a8a3db2ccc4 -> 14560\n",
      "c0a8a3c0a8a32cc4db2c -> 1984\n",
      "c0a8a32c0a8a3a4a0185 -> 14560\n",
      "c0a8a3c0a8a32185a4a0 -> 5888\n",
      "c0a8a9e000fcf6ea14eb -> 1232\n",
      "c0a8a9c0a8a345c27 -> 1152\n",
      "c0a8a9c0a8a3089089 -> 1920\n",
      "c0a8a3c0a8a9089089 -> 1800\n",
      "c0a8a9c0a8a3461bd -> 1360\n",
      "c0a8a3c0a8a91bd46 -> 1040\n",
      "c0a8a19c0a8aff08a08a -> 11712\n",
      "c0a8a32c0a8aff08a08a -> 1150\n",
      "c0a8a19c0a8a3089089 -> 2880\n",
      "c0a8a3c0a8a19089089 -> 2700\n",
      "c0a8a19e000fb14e914e9 -> 3024\n",
      "Total flows =  195\n",
      "Number of malicious flows =  15\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "threshold = 1000\n",
    "\n",
    "# iterate through the flowlist and print those flowids having total volume greater than the threshold\n",
    "count_flows = 0\n",
    "count_malicious = 0\n",
    "\"\"\" WRITE code here \"\"\"\n",
    "for flowid in flowlist:\n",
    "    count_flows += 1\n",
    "    volume = query_cms(flowid)\n",
    "    if(volume>threshold):\n",
    "        print(flowid, '->', volume)\n",
    "        count_malicious += 1\n",
    "\n",
    "print(\"Total flows = \",count_flows)\n",
    "print(\"Number of malicious flows = \", count_malicious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #10FF107f;\">The code above should *again* report that there are 195 FlowIDs in the dataset, of which 15 exceed the allowed bandwidth.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra info\n",
    "Checking whether the threshold is exceeded can be done during the update itself and thereby the malicious flow id can be blacklisted in real-time. \n",
    "\n",
    "To see how the collisions cause overestimation in CM Sketch, change the value of m to 64 in 22.1a and 22.1b(You have to make changes in three places, two in 22.1a and one in 22.1b), and then rerun the exercises 22.1a and 22.1b. Then Run 22.1d below to check the difference. (DO NOT run the cell 22.1c again. Keep the result there so that we can compare the results of 22.1c and 22.1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 22.1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flows =  0\n",
      "Number of malicious flows =  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "threshold = 1000\n",
    "\n",
    "# iterate through the flowlist and print those flowids having total volume greater than the threshold\n",
    "count_flows = 0\n",
    "count_malicious = 0\n",
    "\"\"\" WRITE code here \"\"\"\n",
    "for flowid in flowlist:\n",
    "    count_flows += 1\n",
    "    volume = query_cms(flowid)\n",
    "    if(volume>threshold):\n",
    "        print(flowid, '->', volume)\n",
    "        count_malicious += 1\n",
    "\n",
    "print(\"Total flows = \",count_flows)\n",
    "print(\"Number of malicious flows = \", count_malicious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #10FF107f;\">The code above should report that there are 195 FlowIDs in the dataset, of which 31 exceed the allowed bandwidth.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now 31 more flows are marked as malicious, even though 16 of them are not. This is because of overestimation and this overestimation causes false positives. i.e; there is always a memory vs accuracy trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"30_machine_learning.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
